{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作業 3\n",
    "\n",
    "本作業使用 [Kaggle Titanic](https://www.kaggle.com/c/titanic/overview) 所提供的資料，根據鐵達尼號乘客資料預測生還者。\n",
    "我們只使用 `train.csv` 進行生還者預測（只有 `train.csv` 才有答案），而加分題需要額外使用 `test.csv` 並提交至 [Kaggle Titanic](https://www.kaggle.com/c/titanic/overview) 進行評分。\n",
    "\n",
    "本作業需要先學習[程式教材](https://github.com/IKMLab/course_material)中的以下部份：\n",
    "\n",
    "- [jupyter-基本功能](https://github.com/IKMLab/course_material/blob/master/jupyter-%E5%9F%BA%E6%9C%AC%E5%8A%9F%E8%83%BD.ipynb)\n",
    "- [python-入門語法](https://github.com/IKMLab/course_material/blob/master/python-%E5%85%A5%E9%96%80%E8%AA%9E%E6%B3%95.ipynb)\n",
    "- [numpy-基本功能](https://github.com/IKMLab/course_material/blob/master/numpy-%E5%9F%BA%E6%9C%AC%E5%8A%9F%E8%83%BD.ipynb)\n",
    "- [pandas-基本功能](https://github.com/IKMLab/course_material/blob/master/pandas-%E5%9F%BA%E6%9C%AC%E5%8A%9F%E8%83%BD.ipynb)\n",
    "- [matplotlib-資料視覺化](https://github.com/IKMLab/course_material/blob/master/matplotlib-%E8%B3%87%E6%96%99%E8%A6%96%E8%A6%BA%E5%8C%96.ipynb)\n",
    "- [scikit-learn-基本功能](https://github.com/IKMLab/course_material/blob/master/scikit-learn-%E5%9F%BA%E6%9C%AC%E5%8A%9F%E8%83%BD.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 環境\n",
    "\n",
    "請填寫當前執行使用的環境。\n",
    "\n",
    "|環境|名稱|版本|\n",
    "|-|-|-|\n",
    "|作業系統|Windows|10|\n",
    "|程式執行環境|jupyter notebook|1.0.0|\n",
    "|python 版本|python3|3.6.9|\n",
    "|安裝環境|pip|20.0.2|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 安裝\n",
    "\n",
    "請填寫安裝套件需要的指令\n",
    "\n",
    "pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 參考連結\n",
    "\n",
    "- 有無參考他人之實驗結果：有\n",
    "- 參考連結：https://medium.com/@yulongtsai/https-medium-com-yulongtsai-titanic-top3-8e64741cc11f\n",
    "https://aifreeblog.herokuapp.com/posts/64/Data_Analytics_in_Practice_Titanic/\n",
    "https://medium.com/jameslearningnote/%E8%B3%87%E6%96%99%E5%88%86%E6%9E%90-%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E7%AC%AC4-1%E8%AC%9B-kaggle%E7%AB%B6%E8%B3%BD-%E9%90%B5%E9%81%94%E5%B0%BC%E8%99%9F%E7%94%9F%E5%AD%98%E9%A0%90%E6%B8%AC-%E5%89%8D16-%E6%8E%92%E5%90%8D-a8842fea7077"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 請勿更動此區塊程式碼\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "EXECUTION_START_TIME = time.time() # 計算執行時間\n",
    "df = pd.read_csv('train.csv')    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 資料分析與前處理\n",
    "\n",
    "請在此區塊後使用**一個或多個區塊**進行資料分析與前處理，項目可以包含：\n",
    "\n",
    "- 資料視覺化\n",
    "- 相關係數\n",
    "- 決定輸入特徵\n",
    "- 處理缺失值\n",
    "- 轉換數值\n",
    "- 轉換類別\n",
    "- 其他\n",
    "\n",
    "請以 `markdown` 簡單描述**流程**、**方法**與**原因**：\n",
    "\n",
    "1. 觀察...，發現...\n",
    "2. 填補...，策略...\n",
    "3. 轉換...，原因..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open Price</th>\n",
       "      <th>Close Price</th>\n",
       "      <th>High Price</th>\n",
       "      <th>Low Price</th>\n",
       "      <th>Volume</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05-Jan-2009</td>\n",
       "      <td>929.17</td>\n",
       "      <td>927.45</td>\n",
       "      <td>936.63</td>\n",
       "      <td>919.53</td>\n",
       "      <td>5413910016</td>\n",
       "      <td>-4.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06-Jan-2009</td>\n",
       "      <td>931.17</td>\n",
       "      <td>934.70</td>\n",
       "      <td>943.85</td>\n",
       "      <td>927.28</td>\n",
       "      <td>5392620032</td>\n",
       "      <td>7.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>07-Jan-2009</td>\n",
       "      <td>927.45</td>\n",
       "      <td>906.65</td>\n",
       "      <td>927.45</td>\n",
       "      <td>902.37</td>\n",
       "      <td>4704940032</td>\n",
       "      <td>-28.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08-Jan-2009</td>\n",
       "      <td>905.73</td>\n",
       "      <td>909.73</td>\n",
       "      <td>910.00</td>\n",
       "      <td>896.81</td>\n",
       "      <td>4991549952</td>\n",
       "      <td>3.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>09-Jan-2009</td>\n",
       "      <td>909.91</td>\n",
       "      <td>890.35</td>\n",
       "      <td>911.93</td>\n",
       "      <td>888.31</td>\n",
       "      <td>4716499968</td>\n",
       "      <td>-19.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12-Jan-2009</td>\n",
       "      <td>890.40</td>\n",
       "      <td>870.26</td>\n",
       "      <td>890.40</td>\n",
       "      <td>864.32</td>\n",
       "      <td>4725049856</td>\n",
       "      <td>-20.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13-Jan-2009</td>\n",
       "      <td>869.79</td>\n",
       "      <td>871.79</td>\n",
       "      <td>877.02</td>\n",
       "      <td>862.02</td>\n",
       "      <td>5017469952</td>\n",
       "      <td>1.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14-Jan-2009</td>\n",
       "      <td>867.28</td>\n",
       "      <td>842.62</td>\n",
       "      <td>867.28</td>\n",
       "      <td>836.93</td>\n",
       "      <td>5407880192</td>\n",
       "      <td>-29.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15-Jan-2009</td>\n",
       "      <td>841.99</td>\n",
       "      <td>843.74</td>\n",
       "      <td>851.59</td>\n",
       "      <td>817.04</td>\n",
       "      <td>7807350272</td>\n",
       "      <td>1.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16-Jan-2009</td>\n",
       "      <td>844.45</td>\n",
       "      <td>850.12</td>\n",
       "      <td>858.13</td>\n",
       "      <td>830.66</td>\n",
       "      <td>6786039808</td>\n",
       "      <td>6.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  Open Price  Close Price  High Price  Low Price      Volume  \\\n",
       "1   05-Jan-2009      929.17       927.45      936.63     919.53  5413910016   \n",
       "2   06-Jan-2009      931.17       934.70      943.85     927.28  5392620032   \n",
       "3   07-Jan-2009      927.45       906.65      927.45     902.37  4704940032   \n",
       "4   08-Jan-2009      905.73       909.73      910.00     896.81  4991549952   \n",
       "5   09-Jan-2009      909.91       890.35      911.93     888.31  4716499968   \n",
       "6   12-Jan-2009      890.40       870.26      890.40     864.32  4725049856   \n",
       "7   13-Jan-2009      869.79       871.79      877.02     862.02  5017469952   \n",
       "8   14-Jan-2009      867.28       842.62      867.28     836.93  5407880192   \n",
       "9   15-Jan-2009      841.99       843.74      851.59     817.04  7807350272   \n",
       "10  16-Jan-2009      844.45       850.12      858.13     830.66  6786039808   \n",
       "\n",
       "     diff  \n",
       "1   -4.35  \n",
       "2    7.25  \n",
       "3  -28.05  \n",
       "4    3.08  \n",
       "5  -19.38  \n",
       "6  -20.09  \n",
       "7    1.53  \n",
       "8  -29.17  \n",
       "9    1.12  \n",
       "10   6.38  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 資料分析與前處理\n",
    "\n",
    "import seaborn as sns   \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.impute import SimpleImputer       # 匯入填補缺失值的工具\n",
    "from sklearn.preprocessing import LabelEncoder # 匯入 Label Encoder\n",
    "from matplotlib import pyplot\n",
    "\n",
    "#from pandas import Series\n",
    "model = DecisionTreeClassifier(max_depth = 7) # 叫出一棵決策樹\n",
    "train_x = df[['Date','Open Price', 'Close Price','High Price','Low Price','Volume']]\n",
    "\n",
    "#train_x.index = train_x.Date\n",
    "#df.columns = ['date','open','close','high','low','volume']  #改成 TA-Lib 可以辨識的欄位名稱\n",
    "\n",
    "#df['week_trend'] = np.where(df.4close.shift(-5) > df.close, 1, 0)\n",
    "df['diff'] = df['Close Price']-df['Close Price'].shift(1)\n",
    "df=df.dropna()\n",
    "train_y = df['diff']    \n",
    "df.head(10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#imputer = SimpleImputer(strategy='median')     # 創造 imputer 並設定填補策略\n",
    "#age = train_x['Age'].to_numpy().reshape(-1, 1)\n",
    "#imputer.fit(age)                               # 根據資料學習需要填補的值\n",
    "#train_x['Age'] = imputer.transform(age)        # 填補缺失值\n",
    "\n",
    "#le = LabelEncoder()                            # 創造 Label Encoder\n",
    "#le.fit(train_x['Sex'])                         # 給予每個類別一個數值\n",
    "#train_x['Sex'] = le.transform(train_x['Sex'])  # 轉換所有類別成為數值\n",
    "\n",
    "#sns.countplot(train_x[ 'Pclass' ],hue=df['Survived'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# 對 Fare 欄位取對數\n",
    "df['LogFare'] = np.log1p( df.Fare )\n",
    "\n",
    "# 直方圖(Histogram)\n",
    "fig, axs = plt.subplots( 1,2,figsize=(12,5) )\n",
    "\n",
    "plt.subplot( 1,2,1 )\n",
    "sns.distplot( df.Fare, kde=True, bins=45, color='skyblue', label='bins = 45' )\n",
    "plt.xlabel( 'Fare' ) \n",
    "plt.ylabel( 'Counts' ) \n",
    "plt.legend( )\n",
    "\n",
    "plt.subplot( 1,2,2 )\n",
    "sns.distplot( df.LogFare, kde=True, bins=45, color='skyblue', label='bins = 45' )\n",
    "plt.xlabel( 'Log Fare' ) \n",
    "plt.ylabel( '' ) \n",
    "plt.legend( )\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig, axs = plt.subplots( 1,2,figsize=(12,5) )\n",
    "\n",
    "plt.subplot( 1,2,1 )\n",
    "sns.boxplot( df.Fare, orient='h', color='skyblue' )\n",
    "plt.xlabel( 'Fare' ) \n",
    "\n",
    "plt.subplot( 1,2,2 )\n",
    "sns.boxplot( df.LogFare, orient='h', color='skyblue' )\n",
    "plt.xlabel( 'Log Fare' ) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **乘客票價Fare(Pclass)之資料前處理方式**\n",
    "    - 計算 Fare 欄位的四分位數(Quartile)，且以四分位數對 Fare 欄位進行分組，觀察生存率是否會因票價組別的高低有所差異"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 計算 Fare 欄位各個百分位數(Percentile)\n",
    "P_all = [ np.percentile( df.Fare, q=i ) for i in np.arange(0,101) ] \n",
    "Pth_Percentile = pd.DataFrame( { 'Q':list(range(101)), 'Value':P_all } )\n",
    "\n",
    "# The first、second and third quartile(i,e., the 25th、50th and 75th Percentile)\n",
    "Q1 = Pth_Percentile.iloc[ 25, 1 ]\n",
    "Q2 = Pth_Percentile.iloc[ 50, 1 ]\n",
    "Q3 = Pth_Percentile.iloc[ 75, 1 ]\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "print( f'Q1 = {Q1}' )\n",
    "print( f'Q2 = {Q2} = Median' )\n",
    "print( f'Q3 = {Q3}' )\n",
    "print( f'Maximum = {df.Fare.max()}')\n",
    "print( f'IQR = Q3 - Q1 = {IQR}' )\n",
    "print( f'Q3 + 1.5IQR = {Q3+1.5*IQR}' )\n",
    "\n",
    "# 依照四分位數，對 Fare 欄位進行分組\n",
    "Fare_bin = [ 0, Q1, Q2, Q3, Q3+1.5*IQR, df.Fare.max() ]\n",
    "df[ 'Fare_Group' ] = pd.cut( df.Fare.values, Fare_bin )\n",
    "\n",
    "# 計算每個分組中的資料筆數\n",
    "Group_Counts = df[ 'Fare_Group' ].value_counts().reset_index()    \n",
    "Group_Counts.columns = [ 'Fare_Group', 'Counts' ]\n",
    "Group_Counts.sort_values( by='Fare_Group' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **利用資料視覺化觀察票價與生存率之關係**\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots( figsize=(12,5) )\n",
    "sns.countplot( df.Fare_Group, hue=df.Survived, palette=['lightcoral','skyblue'] )\n",
    "plt.ylabel( 'Counts' ) \n",
    "plt.xticks( rotation=-45, fontsize=12 )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **乘客票價Fare**\n",
    "    - 可看出乘客票價的確對生存率有所影響，票價越高則生存率也越高，因此保留Log對Fare取值，並納入數據中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 刪除 Fare_Group 欄位 \n",
    "df.drop( ['Fare','Fare_Group'], axis=1, inplace=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型訓練\n",
    "\n",
    "請在此區塊後使用**一個或多個區塊**進行模型訓練，**需要**包含以下內容：\n",
    "\n",
    "- **選擇模型**\n",
    "    - 設定模型**超參數**\n",
    "    - **控制隨機亂數**\n",
    "- 計算**準確度（Accuracy）**\n",
    "    - 使用 **5-fold cross validation**，輸出**平均準確度**\n",
    "    - 最後再使用**所有**資料進行訓練並輸出**準確度**\n",
    "    - 準確度必須**超越**課堂使用的範例\n",
    "    \n",
    "如果有進行多於一個以上的實驗，**可以保留所有**的實驗結果，但是執行時間將會納入**全部**實驗。\n",
    "\n",
    "## 模型描述\n",
    "   \n",
    "    使用作業要求的集成方法（ensemble learning）把base estimator组合起来形成Random Forest，以避免偏差及overfit在這邊把n_estimators設定為250棵，數量太小達不到效果，太大的話怕電腦運行太久，min_samples_split設為20，代表若是決策樹的子樹的樣本小於20的話，就不再繼續劃分，以避免overfit，oob_score:因為bagging採取隨機抽樣建立樹模型，未被抽取到的樣本集，可以用來驗證模型效果，在此設定為true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 模型訓練\n",
    "\n",
    "from sklearn.model_selection import KFold             # 匯入 K 次交叉驗證工具\n",
    "from sklearn.tree import DecisionTreeClassifier       # 匯入決策樹模型\n",
    "from sklearn.ensemble import  RandomForestClassifier  #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "from sklearn.metrics import accuracy_score            # 匯入準確度計算工具\n",
    "\n",
    "kf = KFold(n_splits=5,                                # 設定 K 值\n",
    "           random_state=1012,\n",
    "           shuffle=True)\n",
    "kf.get_n_splits(train_x)                              # 給予資料範圍\n",
    "\n",
    "train_acc_list = []                                   # 儲存每次訓練模型的準確度\n",
    "valid_acc_list = []                                   # 儲存每次驗證模型的準確度\n",
    "\n",
    "for train_index, valid_index in kf.split(train_x):    # 每個迴圈都會產生不同部份的資料\n",
    "    train_x_split = train_x.iloc[train_index]         # 產生訓練資料\n",
    "    train_y_split = train_y.iloc[train_index]         # 產生訓練資料標籤\n",
    "    valid_x_split = train_x.iloc[valid_index]         # 產生驗證資料\n",
    "    valid_y_split = train_y.iloc[valid_index]         # 產生驗證資料標籤\n",
    "    \n",
    "    #model = DecisionTreeClassifier(random_state=1012) # 創造決策樹模型\n",
    "    model=RandomForestClassifier(random_state=2,n_estimators=250,min_samples_split=20,oob_score=True) #!!!!!!!!!\n",
    "    model.fit(train_x_split, train_y_split)           # 訓練決策樹模型\n",
    "    \n",
    "    train_pred_y = model.predict(train_x_split)       # 確認模型是否訓練成功\n",
    "    train_acc = accuracy_score(train_y_split,         # 計算訓練資料準確度\n",
    "                               train_pred_y)\n",
    "    valid_pred_y = model.predict(valid_x_split)       # 驗證模型是否訓練成功\n",
    "    valid_acc = accuracy_score(valid_y_split,         # 計算驗證資料準確度\n",
    "                               valid_pred_y)\n",
    "    \n",
    "    train_acc_list.append(train_acc)\n",
    "    valid_acc_list.append(valid_acc)\n",
    "\n",
    "print((\n",
    "    'average train accuracy: {}\\n' +\n",
    "    '    min train accuracy: {}\\n' +\n",
    "    '    max train accuracy: {}\\n' +\n",
    "    'average valid accuracy: {}\\n' +\n",
    "    '    min valid accuracy: {}\\n' +\n",
    "    '    max valid accuracy: {}').format(\n",
    "    np.mean(train_acc_list),                          # 輸出平均訓練準確度\n",
    "    np.min(train_acc_list),                           # 輸出最低訓練準確度\n",
    "    np.max(train_acc_list),                           # 輸出最高訓練準確度\n",
    "    np.mean(valid_acc_list),                          # 輸出平均驗證準確度\n",
    "    np.min(valid_acc_list),                           # 輸出最低驗證準確度\n",
    "    np.max(valid_acc_list)                            # 輸出最高驗證準確度\n",
    "))\n",
    "model.fit(train_x, train_y)                       # 訓練決策樹模型\n",
    "\n",
    "pred_y = model.predict(train_x)                   # 確認模型是否訓練成功\n",
    "acc = accuracy_score(train_y, pred_y)             # 計算準確度\n",
    "\n",
    "print('accuracy with total data : {}'.format(acc))      \n",
    "flag=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **下面的模型**\n",
    "    - 使用SVC(Support Vector Machine)模型\n",
    "    - SVC是 Supervised learning的方法，大多用在統計分類(classification)和回歸分析(regression analysis)。\n",
    "    - 'Embarked'之資料前處理\"由於有缺失資料，因此補上出現次數最多的S，然後再將'Embarked'轉換類別變成數字0,1,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 模型訓練\n",
    "\n",
    "from sklearn.model_selection import KFold             # 匯入 K 次交叉驗證工具\n",
    "from sklearn.tree import DecisionTreeClassifier       # 匯入決策樹模型\n",
    "from sklearn.ensemble import  RandomForestClassifier  #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "from sklearn.metrics import accuracy_score            # 匯入準確度計算工具\n",
    "\n",
    "\n",
    "train_df = pd.read_csv('./train.csv')\n",
    "train_x = train_df[['Sex', 'Age', 'Fare','Pclass','Embarked']]        # 取出訓練資料需要分析的資料欄位\n",
    "train_y = train_df['Survived']                    # 取出訓練資料的答案\n",
    "\n",
    "\n",
    "# 類別型態資料前處理# 數值型態資料前處理\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')        # 創造 imputer 並設定填補策略\n",
    "age = train_x['Age'].to_numpy().reshape(-1, 1)\n",
    "imputer.fit(age)                                  # 根據資料學習需要填補的值\n",
    "train_x['Age'] = imputer.transform(age)           # 填補缺失值\n",
    "\n",
    "# 類別型態資料前處理\n",
    "\n",
    "le = LabelEncoder()                               # 創造 Label Encoder\n",
    "le.fit(train_x['Sex'])                            # 給予每個類別一個數值\n",
    "train_x['Sex'] = le.transform(train_x['Sex'])     # 轉換所有類別成為數值\n",
    "\n",
    "train_x['Embarked']=train_x['Embarked'].fillna('S') #將缺失的'Embarked'補上最多出現的s\n",
    "train_x['Embarked']=train_x['Embarked'].astype('category').cat.codes\n",
    "\n",
    "kf = KFold(n_splits=5,                                # 設定 K 值\n",
    "           random_state=1012,\n",
    "           shuffle=True)\n",
    "\n",
    "kf.get_n_splits(train_x)                              # 給予資料範圍\n",
    "train_x.tail(5) \n",
    "train_acc_list = []                                   # 儲存每次訓練模型的準確度\n",
    "valid_acc_list = []                                   # 儲存每次驗證模型的準確度\n",
    "\n",
    "for train_index, valid_index in kf.split(train_x):    # 每個迴圈都會產生不同部份的資料\n",
    "    train_x_split = train_x.iloc[train_index]         # 產生訓練資料\n",
    "    train_y_split = train_y.iloc[train_index]         # 產生訓練資料標籤\n",
    "    valid_x_split = train_x.iloc[valid_index]         # 產生驗證資料\n",
    "    valid_y_split = train_y.iloc[valid_index]         # 產生驗證資料標籤\n",
    "    \n",
    "    #model = DecisionTreeClassifier(random_state=1012) # 創造決策樹模型\n",
    "    \n",
    "    model = SVC(random_state=1012)                    # 創造支援向量機模型\n",
    "    \n",
    "    model.fit(train_x, train_y)                       # 訓練支援向量機模型\n",
    "    \n",
    "    #model=RandomForestClassifier(random_state=2,n_estimators=250,min_samples_split=20,oob_score=True) #!!!!!!!!!\n",
    "    #model.fit(train_x_split, train_y_split)           # 訓練決策樹模型\n",
    "    \n",
    "    \n",
    "    train_pred_y = model.predict(train_x_split)       # 確認模型是否訓練成功\n",
    "    train_acc = accuracy_score(train_y_split,         # 計算訓練資料準確度\n",
    "                               train_pred_y)\n",
    "    valid_pred_y = model.predict(valid_x_split)       # 驗證模型是否訓練成功\n",
    "    valid_acc = accuracy_score(valid_y_split,         # 計算驗證資料準確度\n",
    "                               valid_pred_y)\n",
    "    \n",
    "    train_acc_list.append(train_acc)\n",
    "    valid_acc_list.append(valid_acc)\n",
    "\n",
    "print((\n",
    "    'average train accuracy: {}\\n' +\n",
    "    '    min train accuracy: {}\\n' +\n",
    "    '    max train accuracy: {}\\n' +\n",
    "    'average valid accuracy: {}\\n' +\n",
    "    '    min valid accuracy: {}\\n' +\n",
    "    '    max valid accuracy: {}').format(\n",
    "    np.mean(train_acc_list),                          # 輸出平均訓練準確度\n",
    "    np.min(train_acc_list),                           # 輸出最低訓練準確度\n",
    "    np.max(train_acc_list),                           # 輸出最高訓練準確度\n",
    "    np.mean(valid_acc_list),                          # 輸出平均驗證準確度\n",
    "    np.min(valid_acc_list),                           # 輸出最低驗證準確度\n",
    "    np.max(valid_acc_list)                            # 輸出最高驗證準確度\n",
    "))\n",
    "model.fit(train_x, train_y)                       # 訓練決策樹模型\n",
    "\n",
    "pred_y = model.predict(train_x)                   # 確認模型是否訓練成功\n",
    "acc = accuracy_score(train_y, pred_y)             # 計算準確度\n",
    "\n",
    "print('accuracy with tatal data : {}'.format(acc))      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加分題\n",
    "\n",
    "請將訓練後的模型套用至 [Kaggle Titanic](https://www.kaggle.com/c/titanic/overview) `test.csv` 上，並上傳至 Kaggle 進行評分，**截圖**後**嵌入**至 `markdown` 區塊中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 請勿更動此區塊程式碼\n",
    "\n",
    "EXECUTION_END_TIME = time.time() # 計算執行時間\n",
    "print('total execution time: {}'.format(EXECUTION_END_TIME - EXECUTION_START_TIME))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
